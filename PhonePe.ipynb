{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import json\n",
    "import requests\n",
    "import psycopg2\n",
    "import plotly.express as py\n",
    "from IPython.display import IFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregated Insurance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aggregated Insurance\n",
    "path = \"C:\\\\Users\\\\karth\\\\OneDrive\\\\Desktop\\\\Cap_Project1\\\\PhonePe Project\\\\pulse\\\\data\\\\aggregated\\\\insurance\\\\country\\\\india\\\\state\\\\\"\n",
    "Aggregated_Insurance_base = os.listdir(path)\n",
    "\n",
    "\n",
    "Tables = [{\"States\": [], \"Years\": [], \"payment_mode\": [], \"Counts\": [], \"Amounts\": [], \"Payment_names\": [], \"Quarter\": []}]\n",
    "\n",
    "\n",
    "for states in Aggregated_Insurance_base:\n",
    "    Aggregated_Insurance_states =path + states + \"\\\\\"\n",
    "    Aggregated_Insurance_years = os.listdir(Aggregated_Insurance_states)\n",
    "\n",
    "    for years in Aggregated_Insurance_years:\n",
    "        Aggregated_Insurance_Year_Path = Aggregated_Insurance_states + years + \"\\\\\"\n",
    "        Aggregated_Insurance_File_list = os.listdir(Aggregated_Insurance_Year_Path)\n",
    "        \n",
    "        for files in Aggregated_Insurance_File_list:\n",
    "            Aggregated_Insurance_Files = Aggregated_Insurance_Year_Path + files\n",
    "            Data = open(Aggregated_Insurance_Files, \"r\")\n",
    "            J = json.load(Data)\n",
    "            \n",
    "\n",
    "\n",
    "            for details in J[\"data\"][\"transactionData\"]:\n",
    "                Name = details[\"name\"]\n",
    "                Count = details[\"paymentInstruments\"][0][\"count\"]\n",
    "                Amount = details[\"paymentInstruments\"][0][\"amount\"]\n",
    "\n",
    "                Tables[0][\"States\"].append(states)\n",
    "                Tables[0][\"Years\"].append(years)\n",
    "                Tables[0][\"payment_mode\"].append(\"TOTAL\")  \n",
    "                Tables[0][\"Counts\"].append(Count)\n",
    "                Tables[0][\"Amounts\"].append(Amount)\n",
    "                Tables[0][\"Payment_names\"].append(Name)\n",
    "                Tables[0][\"Quarter\"].append(int(files.strip(\".json\")))\n",
    "\n",
    "Aggregated_Insurance_DataFrame = pd.DataFrame(Tables[0])\n",
    "Aggregated_Insurance_DataFrame[\"States\"] = Aggregated_Insurance_DataFrame[\"States\"].str.replace(\"andaman-&-nicobar-islands\", \"Andaman & Nicobar\")\n",
    "Aggregated_Insurance_DataFrame[\"States\"] = Aggregated_Insurance_DataFrame[\"States\"].str.replace(\"-\", \" \")\n",
    "Aggregated_Insurance_DataFrame[\"States\"] = Aggregated_Insurance_DataFrame[\"States\"].str.replace(\"Dadra & Nagar Haveli & Daman & Diu\", \"Dadra and Nagar Haveli and Daman and Diu\")\n",
    "Aggregated_Insurance_DataFrame[\"States\"] = Aggregated_Insurance_DataFrame[\"States\"].str.title()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregated Transaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aggregated Transaction\n",
    "\n",
    "path2 = \"C:\\\\Users\\\\karth\\\\OneDrive\\\\Desktop\\\\Cap_Project1\\\\PhonePe Project\\\\pulse\\\\data\\\\aggregated\\\\transaction\\\\country\\\\india\\\\state\\\\\"\n",
    "Aggregated_Transaction_base = os.listdir(path2)\n",
    "\n",
    "\n",
    "Tables2 = [{\"States\": [], \"Years\": [], \"payment_mode\": [], \"Counts\": [], \"Amounts\": [], \"Payment_names\": [], \"Quarter\": []}]\n",
    "\n",
    "\n",
    "for states2 in Aggregated_Transaction_base:\n",
    "    Aggregated_Transaction_states =path2 + states2 + \"\\\\\"\n",
    "    Aggregated_Transaction_years = os.listdir(Aggregated_Transaction_states)\n",
    "\n",
    "    for years2 in Aggregated_Transaction_years:\n",
    "        Aggregated_Transaction_Year_Path = Aggregated_Transaction_states + years2 + \"\\\\\"\n",
    "        Aggregated_Transaction_File_list = os.listdir(Aggregated_Transaction_Year_Path)\n",
    "        \n",
    "        for files2 in Aggregated_Transaction_File_list:\n",
    "            Aggregated_Transaction_Files = Aggregated_Transaction_Year_Path + files2\n",
    "            Data2 = open(Aggregated_Transaction_Files, \"r\")\n",
    "            J2 = json.load(Data2)\n",
    "\n",
    "\n",
    "            for details2 in J2[\"data\"][\"transactionData\"]:\n",
    "                Name = details2[\"name\"]\n",
    "                Count = details2[\"paymentInstruments\"][0][\"count\"]\n",
    "                Amount = details2[\"paymentInstruments\"][0][\"amount\"]\n",
    "\n",
    "                Tables2[0][\"States\"].append(states2)\n",
    "                Tables2[0][\"Years\"].append(years2)\n",
    "                Tables2[0][\"payment_mode\"].append(\"TOTAL\")  # Assuming payment mode is constant\n",
    "                Tables2[0][\"Counts\"].append(Count)\n",
    "                Tables2[0][\"Amounts\"].append(Amount)\n",
    "                Tables2[0][\"Payment_names\"].append(Name)\n",
    "                Tables2[0][\"Quarter\"].append(int(files2.strip(\".json\")))\n",
    "\n",
    "Aggregated_Transaction_DataFrame = pd.DataFrame(Tables2[0])\n",
    "Aggregated_Transaction_DataFrame[\"States\"] = Aggregated_Transaction_DataFrame[\"States\"].str.replace(\"andaman-&-nicobar-islands\", \"Andaman & Nicobar\")\n",
    "Aggregated_Transaction_DataFrame[\"States\"] = Aggregated_Transaction_DataFrame[\"States\"].str.replace(\"-\", \" \")\n",
    "Aggregated_Transaction_DataFrame[\"States\"] = Aggregated_Transaction_DataFrame[\"States\"].str.replace(\"Dadra & Nagar Haveli & Daman & Diu\", \"Dadra and Nagar Haveli and Daman and Diu\")\n",
    "Aggregated_Transaction_DataFrame[\"States\"] = Aggregated_Transaction_DataFrame[\"States\"].str.title()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregated User"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aggregated user\n",
    "path3 = \"C:\\\\Users\\\\karth\\\\OneDrive\\\\Desktop\\\\Cap_Project1\\\\PhonePe Project\\\\pulse\\\\data\\\\aggregated\\\\user\\\\country\\\\india\\\\state\\\\\"\n",
    "Aggregated_user_base = os.listdir(path3)\n",
    "\n",
    "\n",
    "Tables3 = [{\"Brands\": [], \"Counts\": [], \"Percentages\": [], \"States\": [], \"Years\": [], \"Quarter\": []}]\n",
    "\n",
    "\n",
    "for states3 in Aggregated_user_base:\n",
    "    Aggregated_user_states =path3 + states3 + \"\\\\\"\n",
    "    Aggregated_user_years = os.listdir(Aggregated_user_states)\n",
    "\n",
    "    for years3 in Aggregated_user_years:\n",
    "        Aggregated_user_Year_Path = Aggregated_user_states + years3 + \"\\\\\"\n",
    "        Aggregated_user_File_list = os.listdir(Aggregated_user_Year_Path)\n",
    "        \n",
    "        for files3 in Aggregated_user_File_list:\n",
    "            Aggregated_user_Files = Aggregated_user_Year_Path + files3\n",
    "            Data3 = open(Aggregated_user_Files, \"r\")\n",
    "            J3 = json.load(Data3)\n",
    "        \n",
    "            try:\n",
    "                for details3 in J3[\"data\"][\"usersByDevice\"]:\n",
    "                    Brand = details3[\"brand\"]\n",
    "                    Count = details3[\"count\"]\n",
    "                    Percentage = details3[\"percentage\"]\n",
    "                    Tables3[0][\"Brands\"].append(Brand)\n",
    "                    Tables3[0][\"Counts\"].append(Count)\n",
    "                    Tables3[0][\"Percentages\"].append(Percentage)\n",
    "                    Tables3[0][\"States\"].append(states3)\n",
    "                    Tables3[0][\"Years\"].append(years3)\n",
    "                    Tables3[0][\"Quarter\"].append(int(files3.strip(\".json\")))\n",
    "                    \n",
    "                    Aggregated_User_DataFrame = pd.DataFrame(Tables3[0])\n",
    "\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "Aggregated_User_DataFrame = pd.DataFrame(Tables3[0])\n",
    "\n",
    "Aggregated_User_DataFrame[\"States\"] = Aggregated_User_DataFrame[\"States\"].str.replace(\"andaman-&-nicobar-islands\", \"Andaman & Nicobar\")\n",
    "Aggregated_User_DataFrame[\"States\"] = Aggregated_User_DataFrame[\"States\"].str.replace(\"-\", \" \")\n",
    "Aggregated_User_DataFrame[\"States\"] = Aggregated_User_DataFrame[\"States\"].str.replace(\"Dadra & Nagar Haveli & Daman & Diu\", \"Dadra and Nagar Haveli and Daman and Diu\")\n",
    "Aggregated_User_DataFrame[\"States\"] = Aggregated_User_DataFrame[\"States\"].str.title()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Map Insurance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Map Insurance\n",
    "path4 = \"C:\\\\Users\\\\karth\\\\OneDrive\\\\Desktop\\\\Cap_Project1\\\\PhonePe Project\\\\pulse\\\\data\\\\map\\\\insurance\\\\hover\\\\country\\\\india\\\\state\\\\\"\n",
    "Map_Insurance_base = os.listdir(path4)\n",
    "\n",
    "Tables4 = [{\"District_Name\": [], \"Amounts\": [], \"Counts\": [], \"Percentages\": [], \"States\": [], \"Years\": [], \"Quarter\": []}]\n",
    "\n",
    "\n",
    "for states4 in Map_Insurance_base:\n",
    "    Map_Insurance_states =path4 + states4 + \"\\\\\"\n",
    "    Map_Insurance_years = os.listdir(Map_Insurance_states)\n",
    "\n",
    "    for years4 in Map_Insurance_years:\n",
    "        Map_Insurance_Year_Path = Map_Insurance_states + years4 + \"\\\\\"\n",
    "        Map_Insurance_File_list = os.listdir(Map_Insurance_Year_Path)\n",
    "        \n",
    "        for files4 in Map_Insurance_File_list:\n",
    "            Map_Insurance_Files = Map_Insurance_Year_Path + files4\n",
    "            Data4 = open(Map_Insurance_Files, \"r\")\n",
    "            J4 = json.load(Data4)\n",
    "            \n",
    "\n",
    "            for details4 in J4[\"data\"][\"hoverDataList\"]:\n",
    "                Name = details4[\"name\"]\n",
    "                Map_Count = details4[\"metric\"][0][\"count\"]\n",
    "                Map_Amount = details4[\"metric\"][0][\"amount\"]\n",
    "                Tables4[0][\"District_Name\"].append(Name)\n",
    "                Tables4[0][\"Amounts\"].append(Map_Amount)\n",
    "                Tables4[0][\"Counts\"].append(Map_Count)\n",
    "                Tables4[0][\"Percentages\"].append(Percentage)\n",
    "                Tables4[0][\"States\"].append(states4)\n",
    "                Tables4[0][\"Years\"].append(years4)\n",
    "                Tables4[0][\"Quarter\"].append(int(files4.strip(\".json\")))\n",
    "\n",
    "Map_Insurance_DataFrame = pd.DataFrame(Tables4[0])\n",
    "\n",
    "Map_Insurance_DataFrame[\"States\"] = Map_Insurance_DataFrame[\"States\"].str.replace(\"andaman-&-nicobar-islands\", \"Andaman & Nicobar\")\n",
    "Map_Insurance_DataFrame[\"States\"] = Map_Insurance_DataFrame[\"States\"].str.replace(\"-\", \" \")\n",
    "Map_Insurance_DataFrame[\"States\"] = Map_Insurance_DataFrame[\"States\"].str.replace(\"Dadra & Nagar Haveli & Daman & Diu\", \"Dadra and Nagar Haveli and Daman and Diu\")\n",
    "Map_Insurance_DataFrame[\"States\"] = Map_Insurance_DataFrame[\"States\"].str.title()\n",
    "Map_Insurance_DataFrame[\"District_Name\"] = Map_Insurance_DataFrame[\"District_Name\"].str.title()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Map Transaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Map Transaction\n",
    "path5 = \"C:\\\\Users\\\\karth\\\\OneDrive\\\\Desktop\\\\Cap_Project1\\\\PhonePe Project\\\\pulse\\\\data\\\\map\\\\transaction\\\\hover\\\\country\\\\india\\\\state\\\\\"\n",
    "Map_transaction_base = os.listdir(path5)\n",
    "\n",
    "Tables5= [{\"District_Name\": [], \"Amounts\": [], \"Counts\": [], \"Percentages\": [], \"States\": [], \"Years\": [], \"Quarter\": []}]\n",
    "\n",
    "\n",
    "for states5 in Map_transaction_base:\n",
    "    Map_transaction_states =path5 + states5 + \"\\\\\"\n",
    "    Map_transaction_years = os.listdir(Map_transaction_states)\n",
    "\n",
    "    for years5 in Map_transaction_years:\n",
    "        Map_transaction_Year_Path = Map_transaction_states + years5 + \"\\\\\"\n",
    "        Map_transaction_File_list = os.listdir(Map_transaction_Year_Path)\n",
    "        \n",
    "        for files5 in Map_transaction_File_list:\n",
    "            Map_transaction_Files = Map_transaction_Year_Path + files5\n",
    "            Data5 = open(Map_transaction_Files, \"r\")\n",
    "            J5 = json.load(Data5)\n",
    "\n",
    "            for details5 in J5[\"data\"][\"hoverDataList\"]:\n",
    "                Name = details5[\"name\"]\n",
    "                Map_Count = details5[\"metric\"][0][\"count\"]\n",
    "                Map_Amount = details5[\"metric\"][0][\"amount\"]\n",
    "                Tables5[0][\"District_Name\"].append(Name)\n",
    "                Tables5[0][\"Amounts\"].append(Map_Amount)\n",
    "                Tables5[0][\"Counts\"].append(Map_Count)\n",
    "                Tables5[0][\"Percentages\"].append(Percentage)\n",
    "                Tables5[0][\"States\"].append(states5)\n",
    "                Tables5[0][\"Years\"].append(years5)\n",
    "                Tables5[0][\"Quarter\"].append(int(files5.strip(\".json\")))\n",
    "\n",
    "Map_Transaction_DataFrame = pd.DataFrame(Tables5[0])\n",
    "\n",
    "Map_Transaction_DataFrame[\"States\"] = Map_Transaction_DataFrame[\"States\"].str.replace(\"andaman-&-nicobar-islands\", \"Andaman & Nicobar\")\n",
    "Map_Transaction_DataFrame[\"States\"] = Map_Transaction_DataFrame[\"States\"].str.replace(\"-\", \" \")\n",
    "Map_Transaction_DataFrame[\"States\"] = Map_Transaction_DataFrame[\"States\"].str.replace(\"Dadra & Nagar Haveli & Daman & Diu\", \"Dadra and Nagar Haveli and Daman and Diu\")\n",
    "Map_Transaction_DataFrame[\"States\"] = Map_Transaction_DataFrame[\"States\"].str.title()\n",
    "Map_Transaction_DataFrame[\"District_Name\"] = Map_Transaction_DataFrame[\"District_Name\"].str.title()          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Map User"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Map User\n",
    "path6 = \"C:\\\\Users\\\\karth\\\\OneDrive\\\\Desktop\\\\Cap_Project1\\\\PhonePe Project\\\\pulse\\\\data\\\\map\\\\user\\\\hover\\\\country\\\\india\\\\state\\\\\"\n",
    "Map_user_base = os.listdir(path6)\n",
    "\n",
    "Tables6 = [{\"District_Name\": [], \"AppOpens\": [], \"Registers\": [], \"Percentages\": [], \"States\": [], \"Years\": [], \"Quarter\": []}]\n",
    "\n",
    "\n",
    "for states6 in Map_user_base:\n",
    "    Map_user_states =path6 + states6 + \"\\\\\"\n",
    "    Map_user_years = os.listdir(Map_user_states)\n",
    "\n",
    "    for years6 in Map_user_years:\n",
    "        Map_user_Year_Path = Map_user_states + years6 + \"\\\\\"\n",
    "        Map_user_File_list = os.listdir(Map_user_Year_Path)\n",
    "        \n",
    "        for files6 in Map_user_File_list:\n",
    "            Map_user_Files = Map_user_Year_Path + files6\n",
    "            Data6 = open(Map_user_Files, \"r\")\n",
    "            J6 = json.load(Data6)\n",
    "\n",
    "            for details6 in J6[\"data\"][\"hoverData\"].items():\n",
    "                District = details6[0]\n",
    "                Register = details6[1][\"registeredUsers\"]\n",
    "                AppOpen = details6[1][\"appOpens\"]\n",
    "                Tables6[0][\"District_Name\"].append(District)\n",
    "                Tables6[0][\"AppOpens\"].append(AppOpen)\n",
    "                Tables6[0][\"Registers\"].append(Register)\n",
    "                Tables6[0][\"Percentages\"].append(Percentage)\n",
    "                Tables6[0][\"States\"].append(states6)\n",
    "                Tables6[0][\"Years\"].append(years6)\n",
    "                Tables6[0][\"Quarter\"].append(int(files6.strip(\".json\")))\n",
    "\n",
    "Map_User_DataFrame = pd.DataFrame(Tables6[0])\n",
    "\n",
    "Map_User_DataFrame[\"States\"] = Map_User_DataFrame[\"States\"].str.replace(\"andaman-&-nicobar-islands\", \"Andaman & Nicobar\")\n",
    "Map_User_DataFrame[\"States\"] = Map_User_DataFrame[\"States\"].str.replace(\"-\", \" \")\n",
    "Map_User_DataFrame[\"States\"] = Map_User_DataFrame[\"States\"].str.replace(\"Dadra & Nagar Haveli & Daman & Diu\", \"Dadra and Nagar Haveli and Daman and Diu\")\n",
    "Map_User_DataFrame[\"States\"] = Map_User_DataFrame[\"States\"].str.title()\n",
    "Map_User_DataFrame[\"District_Name\"] = Map_User_DataFrame[\"District_Name\"].str.title() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top User"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Top Insurance\n",
    "path7 = \"C:\\\\Users\\\\karth\\\\OneDrive\\\\Desktop\\\\Cap_Project1\\\\PhonePe Project\\\\pulse\\\\data\\\\top\\\\insurance\\\\country\\\\india\\\\state\\\\\"\n",
    "Top_Insurance_base = os.listdir(path7)\n",
    "\n",
    "\n",
    "Tables7 = [{\"EntityName\": [], \"Counts\": [], \"Amounts\": [], \"Percentages\": [], \"States\": [], \"Years\": [], \"Quarter\": []}]\n",
    "\n",
    "\n",
    "for states7 in Top_Insurance_base:\n",
    "    Top_Insurance_states =path7 + states7 + \"\\\\\"\n",
    "    Top_Insurance_years = os.listdir(Top_Insurance_states)\n",
    "\n",
    "    for years7 in Top_Insurance_years:\n",
    "        Top_Insurance_Year_Path = Top_Insurance_states + years7 + \"\\\\\"\n",
    "        Top_Insurance_File_list = os.listdir(Top_Insurance_Year_Path)\n",
    "        \n",
    "        for files7 in Top_Insurance_File_list:\n",
    "            Top_Insurance_Files = Top_Insurance_Year_Path + files7\n",
    "            Data7 = open(Top_Insurance_Files, \"r\")\n",
    "            J7 = json.load(Data7)\n",
    "\n",
    "            for details7 in J7[\"data\"][\"pincodes\"]:\n",
    "                Entity = details7[\"entityName\"]\n",
    "                Count = details7[\"metric\"][\"count\"]\n",
    "                Amount = details7[\"metric\"][\"amount\"]\n",
    "                Tables7[0][\"EntityName\"].append(Entity)\n",
    "                Tables7[0][\"Counts\"].append(Count)\n",
    "                Tables7[0][\"Amounts\"].append(Amount)\n",
    "                Tables7[0][\"Percentages\"].append(Percentage)\n",
    "                Tables7[0][\"States\"].append(states7)\n",
    "                Tables7[0][\"Years\"].append(years7)\n",
    "                Tables7[0][\"Quarter\"].append(int(files7.strip(\".json\")))\n",
    "\n",
    "Top_Insurance_DataFrame = pd.DataFrame(Tables7[0])\n",
    "\n",
    "Top_Insurance_DataFrame[\"States\"] = Top_Insurance_DataFrame[\"States\"].str.replace(\"andaman-&-nicobar-islands\", \"Andaman & Nicobar\")\n",
    "Top_Insurance_DataFrame[\"States\"] = Top_Insurance_DataFrame[\"States\"].str.replace(\"-\", \" \")\n",
    "Top_Insurance_DataFrame[\"States\"] = Top_Insurance_DataFrame[\"States\"].str.replace(\"Dadra & Nagar Haveli & Daman & Diu\", \"Dadra and Nagar Haveli and Daman and Diu\")\n",
    "Top_Insurance_DataFrame[\"States\"] = Top_Insurance_DataFrame[\"States\"].str.title()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top Transaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Top Transaction\n",
    "path8 = \"C:\\\\Users\\\\karth\\\\OneDrive\\\\Desktop\\\\Cap_Project1\\\\PhonePe Project\\\\pulse\\\\data\\\\top\\\\transaction\\\\country\\\\india\\\\state\\\\\"\n",
    "Top_Transaction_base = os.listdir(path8)\n",
    "\n",
    "Tables8 = [{\"EntityName\": [], \"Counts\": [], \"Amounts\": [], \"Percentages\": [], \"States\": [], \"Years\": [], \"Quarter\": []}]\n",
    "\n",
    "\n",
    "for states8 in Top_Transaction_base:\n",
    "    Top_Transaction_states =path8 + states8 + \"\\\\\"\n",
    "    Top_Transaction_years = os.listdir(Top_Transaction_states)\n",
    "\n",
    "    for years8 in Top_Transaction_years:\n",
    "        Top_Transaction_Year_Path = Top_Transaction_states + years8 + \"\\\\\"\n",
    "        Top_Transaction_File_list = os.listdir(Top_Transaction_Year_Path)\n",
    "        \n",
    "        for files8 in Top_Transaction_File_list:\n",
    "            Top_Transaction_Files = Top_Transaction_Year_Path + files8\n",
    "            Data8 = open(Top_Transaction_Files, \"r\")\n",
    "            J8 = json.load(Data8)\n",
    "\n",
    "            for details8 in J8[\"data\"][\"pincodes\"]:\n",
    "                Entity = details8[\"entityName\"]\n",
    "                Count = details8[\"metric\"][\"count\"]\n",
    "                Amount = details8[\"metric\"][\"amount\"]\n",
    "                Tables8[0][\"EntityName\"].append(Entity)\n",
    "                Tables8[0][\"Counts\"].append(Count)\n",
    "                Tables8[0][\"Amounts\"].append(Amount)\n",
    "                Tables8[0][\"Percentages\"].append(Percentage)\n",
    "                Tables8[0][\"States\"].append(states8)\n",
    "                Tables8[0][\"Years\"].append(years8)\n",
    "                Tables8[0][\"Quarter\"].append(int(files8.strip(\".json\")))\n",
    "\n",
    "Top_Transaction_DataFrame = pd.DataFrame(Tables8[0])\n",
    "\n",
    "Top_Transaction_DataFrame[\"States\"] = Top_Transaction_DataFrame[\"States\"].str.replace(\"andaman-&-nicobar-islands\", \"Andaman & Nicobar\")\n",
    "Top_Transaction_DataFrame[\"States\"] = Top_Transaction_DataFrame[\"States\"].str.replace(\"-\", \" \")\n",
    "Top_Transaction_DataFrame[\"States\"] = Top_Transaction_DataFrame[\"States\"].str.replace(\"Dadra & Nagar Haveli & Daman & Diu\", \"Dadra and Nagar Haveli and Daman and Diu\")\n",
    "Top_Transaction_DataFrame[\"States\"] = Top_Transaction_DataFrame[\"States\"].str.title()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top User"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Top User\n",
    "path9 = \"C:\\\\Users\\\\karth\\\\OneDrive\\\\Desktop\\\\Cap_Project1\\\\PhonePe Project\\\\pulse\\\\data\\\\top\\\\user\\\\country\\\\india\\\\state\\\\\"\n",
    "Top_User_base = os.listdir(path9)\n",
    "\n",
    "Tables9 = [{\"EntityName\": [], \"RegisteredUsers\": [], \"Percentages\": [], \"States\": [], \"Years\": [], \"Quarter\": []}]\n",
    "\n",
    "\n",
    "for states9 in Top_User_base:\n",
    "    Top_User_states =path9 + states9 + \"\\\\\"\n",
    "    Top_User_years = os.listdir(Top_User_states)\n",
    "\n",
    "    for years9 in Top_User_years:\n",
    "        Top_User_Year_Path = Top_User_states + years9 + \"\\\\\"\n",
    "        Top_User_File_list = os.listdir(Top_User_Year_Path)\n",
    "        \n",
    "        for files9 in Top_User_File_list:\n",
    "            Top_User_Files = Top_User_Year_Path + files9\n",
    "            Data9 = open(Top_User_Files, \"r\")\n",
    "            J9 = json.load(Data9)\n",
    "\n",
    "            for details9 in J9[\"data\"][\"pincodes\"]:\n",
    "                Entity_Name = details9[\"name\"]\n",
    "                Registeredusers = details9[\"registeredUsers\"]\n",
    "                Tables9[0][\"EntityName\"].append(Entity_Name)\n",
    "                Tables9[0][\"RegisteredUsers\"].append(Registeredusers)\n",
    "                Tables9[0][\"Percentages\"].append(Percentage)\n",
    "                Tables9[0][\"States\"].append(states9)\n",
    "                Tables9[0][\"Years\"].append(years9)\n",
    "                Tables9[0][\"Quarter\"].append(int(files9.strip(\".json\")))\n",
    "\n",
    "Top_User_DataFrame = pd.DataFrame(Tables9[0])\n",
    "\n",
    "Top_User_DataFrame[\"States\"] = Top_User_DataFrame[\"States\"].str.replace(\"andaman-&-nicobar-islands\", \"Andaman & Nicobar\")\n",
    "Top_User_DataFrame[\"States\"] = Top_User_DataFrame[\"States\"].str.replace(\"-\", \" \")\n",
    "Top_User_DataFrame[\"States\"] = Top_User_DataFrame[\"States\"].str.replace(\"Dadra & Nagar Haveli & Daman & Diu\", \"Dadra and Nagar Haveli and Daman and Diu\")\n",
    "Top_User_DataFrame[\"States\"] = Top_User_DataFrame[\"States\"].str.title()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SQL Table Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregated Table Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sql Connection\n",
    "#Aggregated Insurance\n",
    "connection = psycopg2.connect(\n",
    "    database=\"PhonePe\",\n",
    "    user=\"postgres\",\n",
    "    password=\"kk07ch30\",\n",
    "    host=\"localhost\",\n",
    "    port=\"5432\"\n",
    ")\n",
    "\n",
    "Mycursor = connection.cursor()\n",
    "\n",
    "create_query = '''create table if not exists Aggregated_Insurance(\n",
    "States varchar(300),\n",
    "Years int,\n",
    "payment_mode varchar(100),\n",
    "Counts bigint,\n",
    "Amounts bigint,\n",
    "Payment_names varchar(300),\n",
    "Quarter int\n",
    ")'''\n",
    "\n",
    "Mycursor.execute(create_query)\n",
    "connection.commit()\n",
    "\n",
    "\n",
    "insert_query = '''INSERT INTO Aggregated_Insurance (States, Years, payment_mode, Counts, Amounts, Payment_names, Quarter)\n",
    "                  VALUES (%s, %s, %s, %s, %s, %s, %s)'''\n",
    "\n",
    "\n",
    "data = Aggregated_Insurance_DataFrame.values.tolist()\n",
    "Mycursor.executemany(insert_query, data)\n",
    "connection.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sql Connection\n",
    "#Aggregated Transaction\n",
    "connection = psycopg2.connect(\n",
    "    database=\"PhonePe\",\n",
    "    user=\"postgres\",\n",
    "    password=\"kk07ch30\",\n",
    "    host=\"localhost\",\n",
    "    port=\"5432\"\n",
    ")\n",
    "\n",
    "Mycursor = connection.cursor()\n",
    "\n",
    "create_query = '''create table if not exists Aggregated_Transaction(\n",
    "States varchar(300),\n",
    "Years int,\n",
    "payment_mode varchar(100),\n",
    "Counts bigint,\n",
    "Amounts bigint,\n",
    "Payment_names varchar(300),\n",
    "Quarter int\n",
    ")'''\n",
    "\n",
    "Mycursor.execute(create_query)\n",
    "connection.commit()\n",
    "\n",
    "\n",
    "insert_query = '''INSERT INTO Aggregated_Transaction(States, Years, payment_mode, Counts, Amounts, Payment_names, Quarter)\n",
    "                  VALUES (%s, %s, %s, %s, %s, %s, %s)'''\n",
    "\n",
    "\n",
    "data = Aggregated_Transaction_DataFrame.values.tolist()\n",
    "Mycursor.executemany(insert_query, data)\n",
    "connection.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sql Connection\n",
    "#Aggregated User\n",
    "connection = psycopg2.connect(\n",
    "    database=\"PhonePe\",\n",
    "    user=\"postgres\",\n",
    "    password=\"kk07ch30\",\n",
    "    host=\"localhost\",\n",
    "    port=\"5432\"\n",
    ")\n",
    "\n",
    "Mycursor = connection.cursor()\n",
    "\n",
    "create_query = '''create table if not exists Aggregated_User(\n",
    "Brands varchar(300),\n",
    "Counts bigint,\n",
    "Percentages DECIMAL,\n",
    "States varchar(300),\n",
    "Years int,\n",
    "Quarter int\n",
    ")'''\n",
    "\n",
    "Mycursor.execute(create_query)\n",
    "connection.commit()\n",
    "\n",
    "\n",
    "insert_query = '''INSERT INTO Aggregated_User(Brands, Counts, Percentages, States, Years, Quarter)\n",
    "                  VALUES (%s, %s, %s, %s, %s, %s)'''\n",
    "\n",
    "\n",
    "data = Aggregated_User_DataFrame.values.tolist()\n",
    "Mycursor.executemany(insert_query, data)\n",
    "connection.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Map Table Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sql Connection\n",
    "#Map Insurance\n",
    "connection = psycopg2.connect(\n",
    "    database=\"PhonePe\",\n",
    "    user=\"postgres\",\n",
    "    password=\"kk07ch30\",\n",
    "    host=\"localhost\",\n",
    "    port=\"5432\"\n",
    ")\n",
    "\n",
    "Mycursor = connection.cursor()\n",
    "\n",
    "create_query = '''create table if not exists Map_Insurance(\n",
    "District_Name varchar(300),\n",
    "Amounts bigint,\n",
    "Counts bigint ,\n",
    "Percentages DECIMAL,\n",
    "States varchar(300),\n",
    "Years int,\n",
    "Quarter int\n",
    ")'''\n",
    "\n",
    "Mycursor.execute(create_query)\n",
    "connection.commit()\n",
    "\n",
    "\n",
    "insert_query = '''INSERT INTO Map_Insurance(District_Name, Amounts, Counts, Percentages, States, Years, Quarter)\n",
    "                  VALUES (%s, %s, %s, %s, %s, %s, %s)'''\n",
    "\n",
    "\n",
    "data = Map_Insurance_DataFrame.values.tolist()\n",
    "Mycursor.executemany(insert_query, data)\n",
    "connection.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sql Connection\n",
    "#Map Transaction\n",
    "connection = psycopg2.connect(\n",
    "    database=\"PhonePe\",\n",
    "    user=\"postgres\",\n",
    "    password=\"kk07ch30\",\n",
    "    host=\"localhost\",\n",
    "    port=\"5432\"\n",
    ")\n",
    "\n",
    "Mycursor = connection.cursor()\n",
    "\n",
    "create_query = '''create table if not exists Map_Transaction(\n",
    "District_Name varchar(300),\n",
    "Amounts bigint,\n",
    "Counts bigint,\n",
    "Percentages DECIMAL,\n",
    "States varchar(300),\n",
    "Years int,\n",
    "Quarter int\n",
    ")'''\n",
    "\n",
    "Mycursor.execute(create_query)\n",
    "connection.commit()\n",
    "\n",
    "\n",
    "insert_query = '''INSERT INTO Map_Transaction(District_Name, Amounts, Counts, Percentages, States, Years, Quarter)\n",
    "                  VALUES (%s, %s, %s, %s, %s, %s, %s)'''\n",
    "\n",
    "\n",
    "data = Map_Transaction_DataFrame.values.tolist()\n",
    "Mycursor.executemany(insert_query, data)\n",
    "connection.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sql Connection\n",
    "#Map user\n",
    "connection = psycopg2.connect(\n",
    "    database=\"PhonePe\",\n",
    "    user=\"postgres\",\n",
    "    password=\"kk07ch30\",\n",
    "    host=\"localhost\",\n",
    "    port=\"5432\"\n",
    ")\n",
    "\n",
    "Mycursor = connection.cursor()\n",
    "\n",
    "create_query = '''create table if not exists Map_user(\n",
    "District_Name varchar(300),\n",
    "AppOpens int,\n",
    "Registers int,\n",
    "Percentages DECIMAL,\n",
    "States varchar(300),\n",
    "Years int,\n",
    "Quarter int\n",
    ")'''\n",
    "\n",
    "Mycursor.execute(create_query)\n",
    "connection.commit()\n",
    "\n",
    "\n",
    "insert_query = '''INSERT INTO Map_user(District_Name, AppOpens, Registers, Percentages, States, Years, Quarter)\n",
    "                  VALUES (%s, %s, %s, %s, %s, %s, %s)'''\n",
    "\n",
    "\n",
    "data = Map_User_DataFrame.values.tolist()\n",
    "Mycursor.executemany(insert_query, data)\n",
    "connection.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top Table Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sql Connection\n",
    "#Top Insurance\n",
    "connection = psycopg2.connect(\n",
    "    database=\"PhonePe\",\n",
    "    user=\"postgres\",\n",
    "    password=\"kk07ch30\",\n",
    "    host=\"localhost\",\n",
    "    port=\"5432\"\n",
    ")\n",
    "\n",
    "Mycursor = connection.cursor()\n",
    "\n",
    "create_query = '''create table if not exists Top_Insurance(\n",
    "EntityName int,\n",
    "Counts int,\n",
    "Amounts DECIMAL ,\n",
    "Percentages DECIMAL,\n",
    "States varchar(300),\n",
    "Years int,\n",
    "Quarter int\n",
    ")'''\n",
    "\n",
    "Mycursor.execute(create_query)\n",
    "connection.commit()\n",
    "\n",
    "\n",
    "insert_query = '''INSERT INTO Top_Insurance(EntityName, Counts, Amounts, Percentages, States, Years, Quarter)\n",
    "                  VALUES (%s, %s, %s, %s, %s, %s, %s)'''\n",
    "\n",
    "\n",
    "data = Top_Insurance_DataFrame.values.tolist()\n",
    "Mycursor.executemany(insert_query, data)\n",
    "connection.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sql Connection\n",
    "#Top Transaction\n",
    "connection = psycopg2.connect(\n",
    "    database=\"PhonePe\",\n",
    "    user=\"postgres\",\n",
    "    password=\"kk07ch30\",\n",
    "    host=\"localhost\",\n",
    "    port=\"5432\"\n",
    ")\n",
    "\n",
    "Mycursor = connection.cursor()\n",
    "\n",
    "create_query = '''create table if not exists Top_Transaction(\n",
    "EntityName int,\n",
    "Counts int,\n",
    "Amounts bigint,\n",
    "Percentages DECIMAL,\n",
    "States varchar(300),\n",
    "Years int,\n",
    "Quarter int\n",
    ")'''\n",
    "\n",
    "Mycursor.execute(create_query)\n",
    "connection.commit()\n",
    "\n",
    "\n",
    "insert_query = '''INSERT INTO Top_Transaction(EntityName, Counts, Amounts, Percentages, States, Years, Quarter)\n",
    "                  VALUES (%s, %s, %s, %s, %s, %s, %s)'''\n",
    "\n",
    "\n",
    "data = Top_Transaction_DataFrame.values.tolist()\n",
    "Mycursor.executemany(insert_query, data)\n",
    "connection.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sql Connection\n",
    "#Top User\n",
    "connection = psycopg2.connect(\n",
    "    database=\"PhonePe\",\n",
    "    user=\"postgres\",\n",
    "    password=\"kk07ch30\",\n",
    "    host=\"localhost\",\n",
    "    port=\"5432\"\n",
    ")\n",
    "\n",
    "Mycursor = connection.cursor()\n",
    "\n",
    "create_query = '''create table if not exists Top_User(\n",
    "EntityName int,\n",
    "RegisteredUsers int,\n",
    "Percentages DECIMAL,\n",
    "States varchar(300),\n",
    "Years int,\n",
    "Quarter int\n",
    ")'''\n",
    "\n",
    "Mycursor.execute(create_query)\n",
    "connection.commit()\n",
    "\n",
    "\n",
    "insert_query = '''INSERT INTO Top_User(EntityName, RegisteredUsers, Percentages, States, Years, Quarter)\n",
    "                  VALUES (%s, %s, %s, %s, %s, %s)'''\n",
    "\n",
    "\n",
    "data = Top_User_DataFrame.values.tolist()\n",
    "Mycursor.executemany(insert_query, data)\n",
    "connection.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Frame Conversion FOR SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Frame Conversion\n",
    "connection = psycopg2.connect(\n",
    "    database=\"PhonePe\",\n",
    "    user=\"postgres\",\n",
    "    password=\"kk07ch30\",\n",
    "    host=\"localhost\",\n",
    "    port=\"5432\"\n",
    ")\n",
    "\n",
    "Mycursor = connection.cursor()\n",
    "\n",
    "\n",
    "#Aggregated_Insurance_DF\n",
    "Mycursor.execute(\"Select * from aggregated_insurance\")\n",
    "connection.commit()\n",
    "A = Mycursor.fetchall()\n",
    "\n",
    "A_I_DF = pd.DataFrame(A, columns=(\"States\",\"Years\", \"payment_mode\", \"Counts\", \"Amounts\", \"Payment_names\", \"Quarter\"))\n",
    "\n",
    "\n",
    "#Aggregated_Transaction_DF\n",
    "Mycursor.execute(\"Select * from aggregated_transaction\")\n",
    "connection.commit()\n",
    "B = Mycursor.fetchall()\n",
    "\n",
    "A_T_DF = pd.DataFrame(B, columns=(\"States\",\"Years\", \"payment_mode\", \"Counts\", \"Amounts\", \"Payment_names\", \"Quarter\"))\n",
    "\n",
    "\n",
    "#Aggregated_User_DF\n",
    "Mycursor.execute(\"Select * from aggregated_user\")\n",
    "connection.commit()\n",
    "C = Mycursor.fetchall()\n",
    "\n",
    "A_U_DF = pd.DataFrame(C, columns=(\"Brands\",\"Counts\", \"Percentages\", \"States\", \"Years\", \"Quarter\"))\n",
    "\n",
    "\n",
    "#Map_Insurance_DF\n",
    "Mycursor.execute(\"Select * from map_insurance\")\n",
    "connection.commit()\n",
    "D = Mycursor.fetchall()\n",
    "\n",
    "M_I_DF = pd.DataFrame(D, columns=(\"District_Name\",\"Amounts\", \"Counts\", \"Percentages\", \"States\", \"Years\", \"Quarter\"))\n",
    "\n",
    "\n",
    "#Map_Transaction_DF\n",
    "Mycursor.execute(\"Select * from map_transaction\")\n",
    "connection.commit()\n",
    "E = Mycursor.fetchall()\n",
    "\n",
    "M_T_DF = pd.DataFrame(E, columns=(\"District_Name\",\"Amounts\", \"Counts\", \"Percentages\", \"States\", \"Years\", \"Quarter\"))\n",
    "\n",
    "\n",
    "#Map_User_DF\n",
    "Mycursor.execute(\"Select * from map_user\")\n",
    "connection.commit()\n",
    "F = Mycursor.fetchall()\n",
    "\n",
    "M_U_DF = pd.DataFrame(F, columns=(\"District_Name\",\"AppOpens\", \"Registers\", \"Percentages\", \"States\", \"Years\", \"Quarter\"))\n",
    "\n",
    "\n",
    "#Top_Insurance_DF\n",
    "Mycursor.execute(\"Select * from top_insurance\")\n",
    "connection.commit()\n",
    "G = Mycursor.fetchall()\n",
    "\n",
    "T_I_DF = pd.DataFrame(G, columns=(\"EntityName\",\"Counts\", \"Amounts\", \"Percentages\", \"States\", \"Years\", \"Quarter\"))\n",
    "\n",
    "\n",
    "#Top_Transaction_DF\n",
    "Mycursor.execute(\"Select * from top_transaction\")\n",
    "connection.commit()\n",
    "H = Mycursor.fetchall()\n",
    "\n",
    "T_T_DF = pd.DataFrame(H, columns=(\"EntityName\",\"Counts\", \"Amounts\", \"Percentages\", \"States\", \"Years\", \"Quarter\"))\n",
    "\n",
    "\n",
    "#Top_User_DF\n",
    "Mycursor.execute(\"Select * from top_user\")\n",
    "connection.commit()\n",
    "I = Mycursor.fetchall()\n",
    "\n",
    "T_U_DF = pd.DataFrame(I, columns=(\"EntityName\",\"RegisteredUsers\", \"Percentages\", \"States\", \"Years\", \"Quarter\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sql Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Chart - Questions and Answers\n",
    "def Get_TopChart_Amounts(sql):\n",
    "    connection = psycopg2.connect(\n",
    "        database=\"PhonePe\",\n",
    "        user=\"postgres\",\n",
    "        password=\"kk07ch30\",\n",
    "        host=\"localhost\",\n",
    "        port=\"5432\"\n",
    "    )\n",
    "\n",
    "    Mycursor = connection.cursor()\n",
    "\n",
    "    query1 = f'''\n",
    "    select states,\n",
    "    sum(amounts) as \"Transacation Amount\"\n",
    "    from {sql}\n",
    "    group by states\n",
    "    order by \"Transacation Amount\" desc\n",
    "    limit 5'''\n",
    "\n",
    "    Mycursor.execute(query1)\n",
    "    sql1 = Mycursor.fetchall()\n",
    "    connection.commit()\n",
    "\n",
    "    DFQ1 = pd.DataFrame(sql1, columns= (\"States\", \"Transacation Amount\"))\n",
    "    DFQ1.index = range(1,len(DFQ1) + 1)\n",
    "\n",
    "    presentation_amount_Sql1 = py.bar(DFQ1, x=\"States\", y=\"Transacation Amount\", color_discrete_sequence=['purple'], title=f\"Top 5 Transaction Amounts from {sql}\")\n",
    "    presentation_amount_Sql1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Chart - Questions and Answers\n",
    "def Get_BottomChart_Amounts(sql):\n",
    "    connection = psycopg2.connect(\n",
    "        database=\"PhonePe\",\n",
    "        user=\"postgres\",\n",
    "        password=\"kk07ch30\",\n",
    "        host=\"localhost\",\n",
    "        port=\"5432\"\n",
    "    )\n",
    "\n",
    "    Mycursor = connection.cursor()\n",
    "\n",
    "    query2 = f'''\n",
    "    select states,\n",
    "    sum(amounts) as \"Transacation Amount\"\n",
    "    from {sql}\n",
    "    group by states\n",
    "    order by \"Transacation Amount\"\n",
    "    limit 5'''\n",
    "\n",
    "    Mycursor.execute(query2)\n",
    "    sql2 = Mycursor.fetchall()\n",
    "    connection.commit()\n",
    "\n",
    "    DFQ2 = pd.DataFrame(sql2, columns= (\"States\", \"Transacation Amount\"))\n",
    "    DFQ2.index = range(1,len(DFQ2) + 1)\n",
    "\n",
    "    presentation_amount_Sql2 = py.bar(DFQ2, x=\"States\", y=\"Transacation Amount\", color_discrete_sequence=['purple'], title=\"Bottom 5 Transaction\")\n",
    "    st.plotly_chart(presentation_amount_Sql2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Chart - Questions and Answers\n",
    "def Get_AVGChart_Amounts(sql):\n",
    "    connection = psycopg2.connect(\n",
    "        database=\"PhonePe\",\n",
    "        user=\"postgres\",\n",
    "        password=\"kk07ch30\",\n",
    "        host=\"localhost\",\n",
    "        port=\"5432\"\n",
    "    )\n",
    "\n",
    "    Mycursor = connection.cursor()\n",
    "\n",
    "    query3 = f'''\n",
    "    select states,\n",
    "    avg(amounts) as \"Transacation Amount\"\n",
    "    from {sql}\n",
    "    group by states\n",
    "    order by \"Transacation Amount\"'''\n",
    "\n",
    "    Mycursor.execute(query3)\n",
    "    Sql3 = Mycursor.fetchall()\n",
    "    connection.commit()\n",
    "\n",
    "    DFQ3 = pd.DataFrame(Sql3, columns= (\"States\", \"Transacation Amount\"))\n",
    "    DFQ3.index = range(1,len(DFQ3) + 1)\n",
    "\n",
    "    presentation_amount_Sql3 = py.bar(DFQ3, x=\"States\", y=\"Transacation Amount\", color_discrete_sequence=['purple'], title=f\"Average Transaction Amounts from {sql}\")\n",
    "    st.plotly_chart(presentation_amount_Sql3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Chart - Questions and Answers\n",
    "def Get_ALLChart_Counts(sql):\n",
    "    connection = psycopg2.connect(\n",
    "        database=\"PhonePe\",\n",
    "        user=\"postgres\",\n",
    "        password=\"kk07ch30\",\n",
    "        host=\"localhost\",\n",
    "        port=\"5432\"\n",
    "    )\n",
    "\n",
    "    Mycursor = connection.cursor()\n",
    "\n",
    "    query1 = f'''\n",
    "    select states,\n",
    "    sum(counts) as \"Transacation Count\"\n",
    "    from {sql}\n",
    "    group by states\n",
    "    order by \"Transacation Count\" desc\n",
    "    limit 5'''\n",
    "\n",
    "    Mycursor.execute(query1)\n",
    "    sql1 = Mycursor.fetchall()\n",
    "    connection.commit()\n",
    "\n",
    "    DFQ1 = pd.DataFrame(sql1, columns= (\"States\", \"Transacation Amount\"))\n",
    "    DFQ1.index = range(1,len(DFQ1) + 1)\n",
    "\n",
    "    presentation_amount_Sql1 = py.bar(DFQ1, x=\"States\", y=\"Transacation Amount\", color_discrete_sequence=['purple'], title=f\"Top 5 Transaction Counts from {sql}\")\n",
    "    st.plotly_chart(presentation_amount_Sql1)\n",
    "\n",
    "\n",
    "    query2 = f'''\n",
    "    select states,\n",
    "    sum(counts) as \"Transacation Count\"\n",
    "    from {sql}\n",
    "    group by states\n",
    "    order by \"Transacation Count\"\n",
    "    limit 5'''\n",
    "\n",
    "    Mycursor.execute(query2)\n",
    "    Sql2 = Mycursor.fetchall()\n",
    "    connection.commit()\n",
    "\n",
    "    DFQ2 = pd.DataFrame(Sql2, columns= (\"States\", \"Transacation Amount\"))\n",
    "    DFQ2.index = range(1,len(DFQ2) + 1)\n",
    "\n",
    "    presentation_amount_Sql2 = py.bar(DFQ2, x=\"States\", y=\"Transacation Amount\", color_discrete_sequence=['purple'], title=f\"Bottom 5 Transaction Counts from {sql}\")\n",
    "    st.plotly_chart(presentation_amount_Sql2)\n",
    "\n",
    "\n",
    "    query3 = f'''\n",
    "    select states,\n",
    "    avg(counts) as \"Transacation Count\"\n",
    "    from {sql}\n",
    "    group by states\n",
    "    order by \"Transacation Count\"'''\n",
    "\n",
    "    Mycursor.execute(query3)\n",
    "    Sql3 = Mycursor.fetchall()\n",
    "    connection.commit()\n",
    "\n",
    "    DFQ3 = pd.DataFrame(Sql3, columns= (\"States\", \"Transacation Amount\"))\n",
    "    DFQ3.index = range(1,len(DFQ3) + 1)\n",
    "\n",
    "    presentation_amount_Sql3 = py.bar(DFQ3, x=\"States\", y=\"Transacation Amount\", color_discrete_sequence=['purple'], title=f\"Average Transaction Counts from {sql}\")\n",
    "    st.plotly_chart(presentation_amount_Sql3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Chart - Questions and Answers\n",
    "def Get_ALLChart_Registers(sql, state = None):\n",
    "    connection = psycopg2.connect(\n",
    "        database=\"PhonePe\",\n",
    "        user=\"postgres\",\n",
    "        password=\"kk07ch30\",\n",
    "        host=\"localhost\",\n",
    "        port=\"5432\"\n",
    "    )\n",
    "\n",
    "    Mycursor = connection.cursor()\n",
    "\n",
    "    query1 = f'''\n",
    "    select states,district_name,\n",
    "    sum(registers) as total_registered_users\n",
    "    from {sql}\n",
    "    where states = '{state}'\n",
    "    group by states, district_name\n",
    "    order by total_registered_users desc\n",
    "    limit 10;'''\n",
    "\n",
    "    Mycursor.execute(query1)\n",
    "    sql1 = Mycursor.fetchall()\n",
    "    connection.commit()\n",
    "\n",
    "    DFQ1 = pd.DataFrame(sql1, columns=(\"States\", \"District\", \"RegisteredUsers\"))\n",
    "    DFQ1.index = range(1, len(DFQ1) + 1)\n",
    "\n",
    "    presentation_amount_Sql1 = py.bar(DFQ1, x=\"District\", y=\"RegisteredUsers\",\n",
    "                                      hover_name=\"States\", color_discrete_sequence=['purple'],\n",
    "                                      title=f\"Top 10 RegisteredUsers from {state}\")\n",
    "    presentation_amount_Sql1.show()\n",
    "\n",
    "    query2 = f'''\n",
    "    select states,district_name,\n",
    "    sum(registers) as total_registered_users\n",
    "    from {sql}\n",
    "    where states = '{state}'\n",
    "    group by states, district_name\n",
    "    order by total_registered_users\n",
    "    limit 10;'''\n",
    "\n",
    "    Mycursor.execute(query2)\n",
    "    sql2 = Mycursor.fetchall()\n",
    "    connection.commit()\n",
    "\n",
    "    DFQ2 = pd.DataFrame(sql2, columns=(\"States\", \"District\", \"RegisteredUsers\"))\n",
    "    DFQ2.index = range(1, len(DFQ2) + 1)\n",
    "\n",
    "    presentation_amount_Sql2 = py.bar(DFQ2, x=\"District\", y=\"RegisteredUsers\",\n",
    "                                       hover_name=\"States\", color_discrete_sequence=['purple'],\n",
    "                                       title=f\"Bottom 10 RegisteredUsers from {state}\")\n",
    "    presentation_amount_Sql2.show()\n",
    "\n",
    "    query3 = f'''\n",
    "    select states,district_name,\n",
    "    avg(registers) as avg_registered_users\n",
    "    from {sql}\n",
    "    where states = '{state}'\n",
    "    group by states, district_name;'''\n",
    "\n",
    "    Mycursor.execute(query3)\n",
    "    sql3 = Mycursor.fetchall()\n",
    "    connection.commit()\n",
    "\n",
    "    DFQ3 = pd.DataFrame(sql3, columns=(\"States\", \"District\", \"RegisteredUsers\"))\n",
    "    DFQ3.index = range(1, len(DFQ3) + 1)\n",
    "\n",
    "    presentation_amount_Sql3 = py.bar(DFQ3, x=\"District\", y=\"RegisteredUsers\",\n",
    "                                       hover_name=\"States\", color_discrete_sequence=['purple'],\n",
    "                                       width=1000, height=600, title=f\"Average RegisteredUsers from {state}\")\n",
    "    presentation_amount_Sql3.show()\n",
    "\n",
    "    query4 = f'''\n",
    "    select states,district_name,\n",
    "    sum(registers) as total_registered_users\n",
    "    from {sql}\n",
    "    group by states, district_name\n",
    "    order by total_registered_users desc\n",
    "    limit 10;'''\n",
    "\n",
    "    Mycursor.execute(query4)\n",
    "    sql4 = Mycursor.fetchall()\n",
    "    connection.commit()\n",
    "\n",
    "    DFQ4 = pd.DataFrame(sql4, columns=(\"States\", \"District\", \"RegisteredUsers\"))\n",
    "    DFQ4.index = range(1, len(DFQ4) + 1)\n",
    "\n",
    "    presentation_amount_Sql4 = py.bar(DFQ4, x=\"District\", y=\"RegisteredUsers\",\n",
    "                                       hover_name=\"States\", color_discrete_sequence=['purple'],\n",
    "                                       title=\"Top 10 RegisteredUsers from all States\")\n",
    "    presentation_amount_Sql4.show()\n",
    "\n",
    "    query5 = f'''\n",
    "    select states,district_name,\n",
    "    sum(registers) as total_registered_users\n",
    "    from {sql}\n",
    "    group by states, district_name\n",
    "    order by total_registered_users\n",
    "    limit 10;'''\n",
    "\n",
    "    Mycursor.execute(query5)\n",
    "    sql5 = Mycursor.fetchall()\n",
    "    connection.commit()\n",
    "\n",
    "    DFQ5 = pd.DataFrame(sql5, columns=(\"States\", \"District\", \"RegisteredUsers\"))\n",
    "    DFQ5.index = range(1, len(DFQ5) + 1)\n",
    "\n",
    "    presentation_amount_Sql5 = py.bar(DFQ5, x=\"District\", y=\"RegisteredUsers\",\n",
    "                                       hover_name=\"States\", color_discrete_sequence=['purple'],\n",
    "                                       title=\"Bottom 10 RegisteredUsers from all States\")\n",
    "    presentation_amount_Sql5.show()\n",
    "\n",
    "    query6 = f'''\n",
    "    select states,district_name,\n",
    "    avg(registers) as avg_registered_users\n",
    "    from {sql}\n",
    "    group by states, district_name;'''\n",
    "\n",
    "    Mycursor.execute(query6)\n",
    "    sql6 = Mycursor.fetchall()\n",
    "    connection.commit()\n",
    "\n",
    "    DFQ6 = pd.DataFrame(sql6, columns=(\"States\", \"District\", \"RegisteredUsers\"))\n",
    "    DFQ6.index = range(1, len(DFQ6) + 1)\n",
    "\n",
    "    presentation_amount_Sql6 = py.bar(DFQ6, x=\"District\", y=\"RegisteredUsers\",\n",
    "                                       hover_name=\"States\", color_discrete_sequence=['purple'],\n",
    "                                       title=\"Average RegisteredUsers from all States\")\n",
    "    presentation_amount_Sql6.show()\n",
    "\n",
    "    Mycursor.close()\n",
    "    connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Chart - Questions and Answers\n",
    "def Get_ALLChart_Appopens(sql, state = None):\n",
    "    connection = psycopg2.connect(\n",
    "        database=\"PhonePe\",\n",
    "        user=\"postgres\",\n",
    "        password=\"kk07ch30\",\n",
    "        host=\"localhost\",\n",
    "        port=\"5432\"\n",
    "    )\n",
    "\n",
    "    Mycursor = connection.cursor()\n",
    "\n",
    "    query1 = f'''\n",
    "    select states,district_name,\n",
    "    sum(appopens) as total_appopens\n",
    "    from {sql}\n",
    "    where states = '{state}'\n",
    "    group by states, district_name\n",
    "    order by total_appopens desc\n",
    "    limit 10;'''\n",
    "\n",
    "    Mycursor.execute(query1)\n",
    "    sql1 = Mycursor.fetchall()\n",
    "    connection.commit()\n",
    "\n",
    "    DFQ1 = pd.DataFrame(sql1, columns=(\"States\", \"District\", \"AppOpens\"))\n",
    "    DFQ1.index = range(1, len(DFQ1) + 1)\n",
    "\n",
    "    presentation_amount_Sql1 = py.bar(DFQ1, x=\"District\", y=\"AppOpens\",\n",
    "                                      hover_name=\"States\", color_discrete_sequence=['purple'],\n",
    "                                      title=f\"Top 10 AppOpens from {state}\")\n",
    "    presentation_amount_Sql1.show()\n",
    "\n",
    "    query2 = f'''\n",
    "    select states,district_name,\n",
    "    sum(appopens) as total_appopens\n",
    "    from {sql}\n",
    "    where states = '{state}'\n",
    "    group by states, district_name\n",
    "    order by total_appopens\n",
    "    limit 10;'''\n",
    "\n",
    "    Mycursor.execute(query2)\n",
    "    sql2 = Mycursor.fetchall()\n",
    "    connection.commit()\n",
    "\n",
    "    DFQ2 = pd.DataFrame(sql2, columns=(\"States\", \"District\", \"AppOpens\"))\n",
    "    DFQ2.index = range(1, len(DFQ2) + 1)\n",
    "\n",
    "    presentation_amount_Sql2 = py.bar(DFQ2, x=\"District\", y=\"AppOpens\",\n",
    "                                       hover_name=\"States\", color_discrete_sequence=['purple'],\n",
    "                                       title=f\"Bottom 10 AppOpens from {state}\")\n",
    "    presentation_amount_Sql2.show()\n",
    "\n",
    "    query3 = f'''\n",
    "    select states,district_name,\n",
    "    avg(appopens) as avg_appopens\n",
    "    from {sql}\n",
    "    where states = '{state}'\n",
    "    group by states, district_name;'''\n",
    "\n",
    "    Mycursor.execute(query3)\n",
    "    sql3 = Mycursor.fetchall()\n",
    "    connection.commit()\n",
    "\n",
    "    DFQ3 = pd.DataFrame(sql3, columns=(\"States\", \"District\", \"AppOpens\"))\n",
    "    DFQ3.index = range(1, len(DFQ3) + 1)\n",
    "\n",
    "    presentation_amount_Sql3 = py.bar(DFQ3, x=\"District\", y=\"AppOpens\",\n",
    "                                       hover_name=\"States\", color_discrete_sequence=['purple'],\n",
    "                                       width=1000, height=600, title=f\"Average AppOpens from {state}\")\n",
    "    presentation_amount_Sql3.show()\n",
    "\n",
    "    query4 = f'''\n",
    "    select states,district_name,\n",
    "    sum(appopens) as total_appopens\n",
    "    from {sql}\n",
    "    group by states, district_name\n",
    "    order by total_appopens desc\n",
    "    limit 10;'''\n",
    "\n",
    "    Mycursor.execute(query4)\n",
    "    sql4 = Mycursor.fetchall()\n",
    "    connection.commit()\n",
    "\n",
    "    DFQ4 = pd.DataFrame(sql4, columns=(\"States\", \"District\", \"AppOpens\"))\n",
    "    DFQ4.index = range(1, len(DFQ4) + 1)\n",
    "\n",
    "    presentation_amount_Sql4 = py.bar(DFQ4, x=\"District\", y=\"AppOpens\",\n",
    "                                       hover_name=\"States\", color_discrete_sequence=['purple'],\n",
    "                                       title=\"Top 10 AppOpens from all States\")\n",
    "    presentation_amount_Sql4.show()\n",
    "\n",
    "    query5 = f'''\n",
    "    select states,district_name,\n",
    "    sum(appopens) as total_appopens\n",
    "    from {sql}\n",
    "    group by states, district_name\n",
    "    order by total_appopens\n",
    "    limit 10;'''\n",
    "\n",
    "    Mycursor.execute(query5)\n",
    "    sql5 = Mycursor.fetchall()\n",
    "    connection.commit()\n",
    "\n",
    "    DFQ5 = pd.DataFrame(sql5, columns=(\"States\", \"District\", \"AppOpens\"))\n",
    "    DFQ5.index = range(1, len(DFQ5) + 1)\n",
    "\n",
    "    presentation_amount_Sql5 = py.bar(DFQ5, x=\"District\", y=\"AppOpens\",\n",
    "                                       hover_name=\"States\", color_discrete_sequence=['purple'],\n",
    "                                       title=\"Bottom 10 AppOpens from all States\")\n",
    "    presentation_amount_Sql5.show()\n",
    "\n",
    "    query6 = f'''\n",
    "    select states,district_name,\n",
    "    avg(appopens) as avg_appopens\n",
    "    from {sql}\n",
    "    group by states, district_name;'''\n",
    "\n",
    "    Mycursor.execute(query6)\n",
    "    sql6 = Mycursor.fetchall()\n",
    "    connection.commit()\n",
    "\n",
    "    DFQ6 = pd.DataFrame(sql6, columns=(\"States\", \"District\", \"AppOpens\"))\n",
    "    DFQ6.index = range(1, len(DFQ6) + 1)\n",
    "\n",
    "    presentation_amount_Sql6 = py.bar(DFQ6, x=\"District\", y=\"AppOpens\",\n",
    "                                       hover_name=\"States\", color_discrete_sequence=['purple'],\n",
    "                                       title=\"Average AppOpens from all States\")\n",
    "    presentation_amount_Sql6.show()\n",
    "\n",
    "    Mycursor.close()\n",
    "    connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Chart - Questions and Answers\n",
    "def Get_AVGChart_Amounts(sql):\n",
    "    connection = psycopg2.connect(\n",
    "        database=\"PhonePe\",\n",
    "        user=\"postgres\",\n",
    "        password=\"kk07ch30\",\n",
    "        host=\"localhost\",\n",
    "        port=\"5432\"\n",
    "    )\n",
    "\n",
    "    Mycursor = connection.cursor()\n",
    "\n",
    "    query3 = f'''\n",
    "    select states,\n",
    "    avg(amounts) as \"Transacation Amount\"\n",
    "    from {sql}\n",
    "    group by states\n",
    "    order by \"Transacation Amount\"'''\n",
    "\n",
    "    Mycursor.execute(query3)\n",
    "    Sql3 = Mycursor.fetchall()\n",
    "    connection.commit()\n",
    "\n",
    "    DFQ3 = pd.DataFrame(Sql3, columns= (\"States\", \"Transacation Amount\"))\n",
    "    DFQ3.index = range(1,len(DFQ3) + 1)\n",
    "\n",
    "    presentation_amount_Sql3 = py.bar(DFQ3, x=\"States\", y=\"Transacation Amount\", color_discrete_sequence=['purple'], title=f\"Average Transaction Amounts from {sql}\")\n",
    "    st.plotly_chart(presentation_amount_Sql3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_payment_modes_counts(sql,state):\n",
    "    connection = psycopg2.connect(\n",
    "        database=\"PhonePe\",\n",
    "        user=\"postgres\",\n",
    "        password=\"kk07ch30\",\n",
    "        host=\"localhost\",\n",
    "        port=\"5432\"\n",
    "    )\n",
    "    Mycursor = connection.cursor()\n",
    "    query = f'''\n",
    "    select states, \n",
    "    sum(counts) as count,\n",
    "    payment_names\n",
    "    from {sql}\n",
    "    where states = '{state}'\n",
    "    group by states,payment_names\n",
    "    order by states\n",
    "    '''\n",
    "    Mycursor.execute(query)\n",
    "    data = Mycursor.fetchall()\n",
    "    connection.commit\n",
    "\n",
    "    DFQ3 = pd.DataFrame(data, columns= (\"States\", \"count\", \"payment_names\"))\n",
    "    DFQ3.index = range(1,len(DFQ3) + 1)\n",
    "\n",
    "    presentation_payment = py.bar(DFQ3, x=\"States\", y=\"payment_names\", color_discrete_sequence=['purple'], title=f\"Average Transaction Amounts from {sql}\")\n",
    "    st.plotly_chart(presentation_payment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FINAL DATAFRAMES FOR STREAMLIT "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aggregated Insurance\n",
    "def DataFrame_S_C_A_by_year(DF, Year):\n",
    "        output_Y = DF[DF[\"Years\"]==Year]\n",
    "        output_Y.reset_index(drop = True, inplace = True)\n",
    "\n",
    "        output_Y_GroupBy = output_Y.groupby(\"States\")[[\"Counts\", \"Amounts\"]].sum()\n",
    "        output_Y_GroupBy.reset_index(inplace = True)\n",
    "\n",
    "        presentation_amount = py.bar(output_Y_GroupBy, x=\"States\", y=\"Amounts\", color_discrete_sequence=['purple'], title=f\"{Year} - Bar Chart of Amounts by State\")\n",
    "        presentation_amount.show()\n",
    "\n",
    "        presentation_count = py.bar(output_Y_GroupBy, x=\"States\", y=\"Counts\", color_discrete_sequence=['green'], title=f\"{Year} - Bar Chart of Counts by State\")\n",
    "        presentation_count.show()\n",
    "   \n",
    "\n",
    "\n",
    "        url = \"https://gist.githubusercontent.com/jbrobst/56c13bbbf9d97d187fea01ca62ea5112/raw/e388c4cae20aa53cb5090210a42ebb9b765c0a36/india_states.geojson\"\n",
    "        response = requests.get(url)\n",
    "        j_response = json.loads(response.content)\n",
    "\n",
    "        state_list = []\n",
    "        for info in j_response[\"features\"]:\n",
    "            state_list.append(info['properties']['ST_NM'])\n",
    "\n",
    "        state_list.sort()\n",
    "\n",
    "        presentation_India = py.choropleth(output_Y_GroupBy, geojson= j_response, locations= \"States\", \n",
    "                                           featureidkey= \"properties.ST_NM\", color= \"Amounts\", color_continuous_scale= \"Rainbow\", \n",
    "                                           range_color= (output_Y_GroupBy[\"Amounts\"].min(), output_Y_GroupBy[\"Amounts\"].max()),\n",
    "                                           hover_name= \"States\", title= f\"{Year} - Transaction Amount\", fitbounds= \"locations\")\n",
    "        \n",
    "        presentation_India.update_geos(visible = False)\n",
    "        presentation_India.show()\n",
    "\n",
    "        presentation_India2 = py.choropleth(output_Y_GroupBy, geojson= j_response, locations= \"States\", \n",
    "                                           featureidkey= \"properties.ST_NM\", color= \"Counts\", color_continuous_scale= \"Rainbow\", \n",
    "                                           range_color= (output_Y_GroupBy[\"Counts\"].min(), output_Y_GroupBy[\"Counts\"].max()),\n",
    "                                           hover_name= \"States\", title= f\"{Year} - Transaction Count\", fitbounds= \"locations\")\n",
    "        \n",
    "        presentation_India2.update_geos(visible = False)\n",
    "        presentation_India2.show()\n",
    "\n",
    "        return output_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aggregated Insurance\n",
    "def DataFrame_S_C_A_by_Quarter(DF, Quarters):\n",
    "        output_Y = DF[DF[\"Quarter\"]==Quarters]\n",
    "        output_Y.reset_index(drop = True, inplace = True)\n",
    "\n",
    "        output_Y_GroupBy = output_Y.groupby(\"States\")[[\"Counts\", \"Amounts\"]].sum()\n",
    "        output_Y_GroupBy.reset_index(inplace = True)\n",
    "\n",
    "        presentation_amount = py.bar(output_Y_GroupBy, x=\"States\", y=\"Amounts\",\n",
    "                                      color_discrete_sequence=['purple'],\n",
    "                                        title=f\"{output_Y[\"Years\"].min()} YEAR, {Quarters} Quarter's - Bar Chart of Amounts by State\")\n",
    "        presentation_amount.show()\n",
    "\n",
    "        presentation_count = py.bar(output_Y_GroupBy, x=\"States\", y=\"Counts\",\n",
    "                                     color_discrete_sequence=['green'],\n",
    "                                       title=f\"{output_Y[\"Years\"].min()} YEAR, {Quarters} Quarter's - Bar Chart of Counts by State\")\n",
    "        presentation_count.show()\n",
    "   \n",
    "\n",
    "\n",
    "        url = \"https://gist.githubusercontent.com/jbrobst/56c13bbbf9d97d187fea01ca62ea5112/raw/e388c4cae20aa53cb5090210a42ebb9b765c0a36/india_states.geojson\"\n",
    "        response = requests.get(url)\n",
    "        j_response = json.loads(response.content)\n",
    "\n",
    "        state_list = []\n",
    "        for info in j_response[\"features\"]:\n",
    "            state_list.append(info['properties']['ST_NM'])\n",
    "\n",
    "        state_list.sort()\n",
    "\n",
    "        presentation_India = py.choropleth(output_Y_GroupBy, geojson= j_response, locations= \"States\", \n",
    "                                           featureidkey= \"properties.ST_NM\", color= \"Amounts\", color_continuous_scale= \"Rainbow\", \n",
    "                                           range_color= (output_Y_GroupBy[\"Amounts\"].min(), output_Y_GroupBy[\"Amounts\"].max()),\n",
    "                                           hover_name= \"States\", title= f\"{output_Y[\"Years\"].unique()} YEAR {Quarters} - Transaction Amount\", fitbounds= \"locations\")\n",
    "        \n",
    "        presentation_India.update_geos(visible = False)\n",
    "        presentation_India.show()\n",
    "\n",
    "        presentation_India2 = py.choropleth(output_Y_GroupBy, geojson= j_response, locations= \"States\", \n",
    "                                           featureidkey= \"properties.ST_NM\", color= \"Counts\", color_continuous_scale= \"Rainbow\", \n",
    "                                           range_color= (output_Y_GroupBy[\"Counts\"].min(), output_Y_GroupBy[\"Counts\"].max()),\n",
    "                                           hover_name= \"States\", title= f\"{output_Y[\"Years\"].unique()} YEAR {Quarters} - Transaction Count\", fitbounds= \"locations\")\n",
    "        \n",
    "        presentation_India2.update_geos(visible = False)\n",
    "        presentation_India2.show()\n",
    "\n",
    "        return output_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aggregated Transaction\n",
    "def DataFrame_S_C_A_by_year2(DF, state):\n",
    "    output_Y2 = DF[DF[\"States\"] == state]\n",
    "    output_Y2.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    output_Y2_GroupBy = output_Y2.groupby(\"Payment_names\")[[\"Counts\", \"Amounts\"]].sum()\n",
    "    output_Y2_GroupBy.reset_index(inplace= True)\n",
    "\n",
    "\n",
    "    fig_pie1 = py.pie(data_frame= output_Y2_GroupBy, names= \"Payment_names\", values= \"Amounts\",\n",
    "                    title= f\"{state.upper()} - Pie Chart of Amounts From Aggregated Transaction\", hole= 0.5)\n",
    "    fig_pie1.show()\n",
    "\n",
    "    fig_pie2 = py.pie(data_frame= output_Y2_GroupBy, names= \"Payment_names\", values= \"Counts\",\n",
    "                    title= f\"{state} - Pie Chart of Counts From Aggregated Transaction\", hole= 0.5)\n",
    "    fig_pie2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aggregated User\n",
    "def DataFrame_S_C_A_by_year3(DF, Year):\n",
    "    output_Y3 = DF[DF[\"Years\"] == Year]\n",
    "    output_Y3.reset_index(drop= True, inplace= True)\n",
    "\n",
    "    output_Y3_GroupBy = pd.DataFrame(output_Y3.groupby(\"Brands\")[[\"Counts\", \"Percentages\"]].sum())\n",
    "    output_Y3_GroupBy.reset_index(inplace= True)\n",
    "\n",
    "    presentation_3_DF = py.bar(output_Y3_GroupBy, x=\"Brands\", y=\"Counts\",\n",
    "                            color_discrete_sequence=['blue'],\n",
    "                            title=\"Bar chart Of Brands And Counts for Aggregated User\")\n",
    "\n",
    "    presentation_3_DF.show()\n",
    "    return output_Y3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aggregated User\n",
    "def DataFrame_S_C_A_by_Quarter3(DF, Quarters):\n",
    "    output_Y3_Q = DF[DF[\"Quarter\"] == Quarters]\n",
    "    output_Y3_Q.reset_index(drop= True, inplace= True)\n",
    "\n",
    "    output_Y3_Q_GroupBy = pd.DataFrame(output_Y3_Q.groupby([\"Brands\", \"States\"])[[\"Counts\"]].sum())\n",
    "    output_Y3_Q_GroupBy.reset_index(inplace= True)\n",
    "\n",
    "\n",
    "    presentation_3_DF_AU = py.bar(output_Y3_Q_GroupBy,\n",
    "                                x=\"Brands\", y=\"Counts\",\n",
    "                                color_discrete_sequence=['blue'],\n",
    "                                hover_name = \"States\",\n",
    "                                title=f\"{output_Y3_Q[\"Years\"].min()} YEAR {Quarters} Quarter's - Bar chart Of Brands And Counts\")\n",
    "\n",
    "    presentation_3_DF_AU.show()\n",
    "    return output_Y3_Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aggregated User\n",
    "def DataFrame_S_C_A_by_year3_State(DF, state):\n",
    "    output_Y3_Q_S =  DF[DF[\"States\"] == state]\n",
    "    output_Y3_Q_S.reset_index(drop = True, inplace = True)\n",
    "\n",
    "    presentation_3_S = py.line(output_Y3_Q_S, x = \"Brands\", y = \"Counts\", hover_data= \"Percentages\",\n",
    "                            title = \"Line Chart for Brands in States\",\n",
    "                            markers = True)\n",
    "\n",
    "    presentation_3_S.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Map Insurance\n",
    "def DataFrame_D_C_A_by_year4(DF, state):\n",
    "    output_Y4 = DF[DF[\"States\"] == state]\n",
    "    output_Y4.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    output_Y4_GroupBy = output_Y4.groupby(\"District_Name\")[[\"Amounts\", \"Counts\"]].sum()\n",
    "    output_Y4_GroupBy.reset_index(inplace= True)\n",
    "\n",
    "\n",
    "    fig_bar4 = py.bar(output_Y4_GroupBy,\n",
    "                        x=\"Amounts\", y=\"District_Name\",\n",
    "                        color_discrete_sequence=['blue'], orientation= \"h\",\n",
    "                        hover_name = \"District_Name\",\n",
    "                        title=f\"{output_Y4[\"Years\"].min()} YEAR, {state} States - Bar chart Of Amounts\")\n",
    "    \n",
    "    fig_bar4.update_yaxes(tickfont=dict(size=7))\n",
    "    fig_bar4.show()\n",
    "\n",
    "    fig_bar4 = py.bar(output_Y4_GroupBy,\n",
    "                        x=\"Counts\", y=\"District_Name\",\n",
    "                        color_discrete_sequence=['blue'],\n",
    "                        hover_name = \"District_Name\",\n",
    "                        title=f\"{output_Y4[\"Years\"].min()} YEAR, {state} States - Bar chart Of Counts\")\n",
    "    \n",
    "    fig_bar4.update_yaxes(tickfont=dict(size=7))\n",
    "    fig_bar4.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Map User\n",
    "def DataFrame_S_C_A_by_year6(DF, Year):\n",
    "    output_Y6 = DF[DF[\"Years\"] == Year]\n",
    "    output_Y6.reset_index(drop= True, inplace= True)\n",
    "\n",
    "    output_Y6_GroupBy = pd.DataFrame(output_Y6.groupby([\"States\", \"District_Name\"])[[\"Registers\", \"AppOpens\"]].sum())\n",
    "    output_Y6_GroupBy.reset_index(inplace= True)\n",
    "    output_Y6_GroupBy\n",
    "\n",
    "    presentation_Y6 = py.line(output_Y6_GroupBy, x = \"States\", y = [\"Registers\", \"AppOpens\"], hover_data= \"District_Name\",\n",
    "                                color_discrete_sequence=['blue', 'green'], title = \"Line Chart for Registers & AppOpens\",\n",
    "                                markers = True)\n",
    "\n",
    "    presentation_Y6.show()\n",
    "\n",
    "    return output_Y6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Map User\n",
    "def DataFrame_S_C_A_by_Q6(DF, quarter):\n",
    "    output_Q6 = DF[DF[\"Quarter\"] == quarter]\n",
    "    output_Q6.reset_index(drop= True, inplace= True)\n",
    "\n",
    "    output_Q6_GroupBy = pd.DataFrame(output_Q6.groupby([\"States\", \"District_Name\"])[[\"Registers\", \"AppOpens\"]].sum())\n",
    "    output_Q6_GroupBy.reset_index(inplace= True)\n",
    "    # output_Q6_GroupBy\n",
    "\n",
    "    presentation_Q6 = py.line(output_Q6_GroupBy, x = \"States\", y = [\"Registers\", \"AppOpens\"], hover_data= \"District_Name\",\n",
    "                                color_discrete_sequence=['blue', 'green'], title = f\"{quarter} QUARTER - Line Chart for Registers & AppOpens\",\n",
    "                                markers = True)\n",
    "\n",
    "    presentation_Q6.show()\n",
    "\n",
    "    return output_Q6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Map User\n",
    "def DataFrame_D_C_A_by_state6(DF, state):\n",
    "    output_S6 = DF[DF[\"States\"] == state]\n",
    "    output_S6.reset_index(drop=True, inplace=True)\n",
    "\n",
    "\n",
    "        # output_Y4_GroupBy = output_Y4.groupby(\"District_Name\")[[\"Amounts\", \"Counts\"]].sum()\n",
    "        # output_Y4_GroupBy.reset_index(inplace= True)\n",
    "\n",
    "\n",
    "    Presentation_Reg_S6 = py.bar(output_S6,\n",
    "                        x=\"Registers\", y=\"District_Name\",\n",
    "                        color_discrete_sequence=['blue'], orientation= \"h\",\n",
    "                        hover_name = \"States\",\n",
    "                        title=f\"{output_S6[\"Years\"].min()} YEAR, States - Bar chart Of Register Users\")\n",
    "\n",
    "    Presentation_Reg_S6.update_yaxes(tickfont=dict(size=11))\n",
    "    Presentation_Reg_S6.show()\n",
    "    # st.plotly_chart(fig_bar_S6)\n",
    "\n",
    "\n",
    "    Presentation_App_S6 = py.bar(output_S6,\n",
    "                        x=\"AppOpens\", y=\"District_Name\",\n",
    "                        color_discrete_sequence=['blue'], orientation= \"h\",\n",
    "                        hover_name = \"States\",\n",
    "                        title=\"Bar chart Of AppOppens\")\n",
    "\n",
    "    Presentation_App_S6.update_yaxes(tickfont=dict(size=11))\n",
    "    Presentation_App_S6.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DataFrame_S_C_A_by_State7(DF, states):\n",
    "    output_Y7_Q = DF[DF[\"States\"] == states]\n",
    "    output_Y7_Q.reset_index(drop= True, inplace= True)\n",
    "\n",
    "    output_Y7_Q_GroupBy = pd.DataFrame(output_Y7_Q.groupby(\"EntityName\")[[\"Counts\", \"Amounts\"]].sum())\n",
    "    output_Y7_Q_GroupBy.reset_index(inplace= True)\n",
    "\n",
    "\n",
    "    presentation7S = py.bar(output_Y7_Q,\n",
    "                                x=\"Quarter\", y=\"Amounts\",\n",
    "                                color_discrete_sequence=['blue'], height= 800, hover_data= \"EntityName\",\n",
    "                                title=f\"{output_Y7_Q[\"Years\"].min()} YEAR, {output_Y7_Q[\"States\"].min()} STATES - Bar chart Of Amounts\")\n",
    "\n",
    "    # st.plotly_chart(presentation7S)\n",
    "    presentation7S.show()\n",
    "    return output_Y7_Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Top User\n",
    "def DataFrame_S_C_A_by_Year9(DF, year):\n",
    "    output_Y9_Q = DF[DF[\"Years\"] == year]\n",
    "    output_Y9_Q.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    output_Y9_Q_GroupBy = pd.DataFrame(output_Y9_Q.groupby([\"States\", \"Quarter\"])[\"RegisteredUsers\"].sum())\n",
    "    output_Y9_Q_GroupBy.reset_index(inplace=True)\n",
    "\n",
    "    presentation9 = py.bar(output_Y9_Q_GroupBy, x=\"States\", y=\"RegisteredUsers\", color=\"Quarter\",\n",
    "                            title=f\"{output_Y9_Q['Years'].min()} YEAR - Bar chart Of Registered Users\",\n",
    "                            labels={\"RegisteredUsers\": \"Registered Users\"},\n",
    "                            color_discrete_map={1: \"blue\", 2: \"green\", 3: \"red\", 4: \"orange\"},\n",
    "                            hover_name= \"States\")\n",
    "\n",
    "    presentation9.show()\n",
    "\n",
    "    # st.plotly_chart(presentation9)\n",
    "    return output_Y9_Q\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DataFrame_S_C_A_by_S9(DF, state):\n",
    "    output_S9 = DF[DF[\"States\"] == state]\n",
    "    output_S9.reset_index(drop= True, inplace= True)\n",
    "\n",
    "\n",
    "    presentation_S9 = py.bar(output_S9, x = \"Quarter\", y = \"RegisteredUsers\",\n",
    "                            title= \"Bar chart for Registered Users\", color=\"RegisteredUsers\",\n",
    "                            color_discrete_map={1: \"blue\", 2: \"orange\", 3: \"red\", 4: \"green\"},\n",
    "                            hover_data= \"EntityName\")\n",
    "\n",
    "    presentation_S9.show()\n",
    "    # st.plotly_chart(presentation_S9)\n",
    "\n",
    "    # return output_S9"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
